\section{Модель}
Два игрока с противоположными интересами имеют деньги и однотипные акции. Случайная цена акции может принимать либо значение $ m $ в состоянии $ H $, либо $ 0 $ в состоянии $ L $ и определяется на весь период торгов на первом шаге ходом случая. Первый игрок осведомлен о результате случайного хода, второй игрок знает только вероятность выбора того или иного состояния. 
Второй игрок знает, что первый является инсайдером.
На каждом последующем шаге игроки одновременно предлагают свою цену за одну акцию. Игрок, назвавший большую цену покупает у другого игрока акцию, по цене равной полусумме предложенных цен. В случае одинаковых ставок транзакции не происходит.

Данную модель торгов можно рассматривать как повторяющуюся игру с неполной информацией. Подобные игры были впервые рассмотрены Р. Ауманом и М. Машлером (см. [\aumann]). Игра задается множеством состояний, каждому состоянию соответствует матричная игра, где матрицу можно рассматривать как матрицу выигрышей первого игрока.

Таким образом мы приходим к следующей формализации рассматриваемой модели.
Множество состояний $ S = \{H, L\} $. На первом шаге случай выбирает $ s \in S $ с вероятностями $ p(H) = p $ и $ p(L) = (1 - p) $.
После этого на протяжении $ n \leq \infty $ шагов игроки играют в игру $ A^s $.
Соответствующие платежные матрицы задаются следующим образом:
\begin{eqnarray*}
A^L(i, j) &=& \frac{1}{m}\begin{cases}
\frac{i+j}{2}, &\, i < j, \\
0, &\, i = j, \\
-\frac{i+j}{2}, &\, i > j,
\end{cases}
\\
A^H(i, j) &=& \frac{1}{m}\begin{cases}
\frac{i+j}{2} - m, &\, i < j, \\
0, &\, i = j, \\
m - \frac{i+j}{2}, &\, i > j.
\end{cases}
\end{eqnarray*}



Множество возможных ставок первого и второго игроков:
\[
  i \in I = \{0, 1, \ldots, m\}, \;
  j \in J = \{0, 1, \ldots, m\}.
\]
Тогда стратегией первого игрока является последовательность ходов
\[
  \sigma = (\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots),
\]
где $ \sigma_t: S \times I^{t-1} \rightarrow \Delta(I) $, а $ \Delta(I) $ --- вероятностное распределение на множестве возможных ставок. Множество всевозможных стратегий первого игрока обозначим через $ \Sigma $.

Аналогично стратегией второго игрока назовем последовательность ходов
\[
  \tau = (\tau_1, \tau_2, \ldots, \tau_t, \ldots),
\]
где $ \tau_t: I^{t-1} \rightarrow \Delta(J) $. Множество всевозможных стратегий второго игрока обозначим через $ \Tau $.

Для упрощения вычислений умножим платежные матрицы на $ 2m $, сохранив обозначения:
\begin{eqnarray}
\label{eq:payoff_matrix_h}
A^L(i, j) &=& \begin{cases}
  i + j, &\, i < j, \\
  0, &\, i = j, \\
  -i - j, &\, i > j,
\end{cases}
\\
\label{eq:payoff_matrix_l}
A^H(i, j) &=& \begin{cases}
  i + j - 2m, &\, i < j, \\
  0, &\, i = j, \\
  2m - i - j, &\, i > j.
\end{cases}
\end{eqnarray}

В дальнейшем будем рассматривать повторяющуюся игру именно с матрицами \eqref{eq:payoff_matrix_h} и \eqref{eq:payoff_matrix_l}, которую назовем $ G_n^m(p) $. При применении первым игроков смешанной стратегий 
$ \sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n) $, где 
\[ 
  \sigma_t = (\sigma_t^L, \sigma_t^H), \quad
  \sigma^s_t = (\sigma^s_{t, 1}, \ldots, \sigma^s_{t, m}) \in \Delta(I),
\] 
а вторым игроком смешанной стратегии 
$ \tau = (\tau_1, \tau_2, \ldots, \tau_n) $, где
$ \tau_t~=~(\tau_{t, 1}, \ldots, \tau_{t, m}) \in \Delta(J) $,
выигрыш равен
\begin{equation}
\label{eq:value_of_game_n}
K_n^m(p, \sigma, \tau) = \sum_{t=1}^n
    \left(
        pA^H(\sigma_t^H, \tau_t) + (1 - p)A^L(\sigma_t^L, \tau_t)
    \right),
\end{equation}
где 
$ 
  A^s(\sigma^s_t,\tau_t) = 
    \sum_{i \in I}
      \sum_{j \in J}
        \sigma^s_{t, i} \tau_{t, j} A^s(i, j).
$