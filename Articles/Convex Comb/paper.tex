% -*- coding: cp866 -*-
%
% ****** maiksamp.tex 29.11.2001 ******
%
\documentclass[
aps,%
12pt,%
final,%
notitlepage,%
oneside,%
onecolumn,%
nobibnotes,%
nofootinbib,% 
superscriptaddress,%
noshowpacs,%
centertags]%
{revtex4}

\bibliographystyle{maik}

\begin{document}
\selectlanguage{russian}

\title{МОДЕЛЬ БИРЖЕВЫХ ТОРГОВ С ИНСАЙДЕРОМ\\
С ЭЛЕМЕНТАМИ ПЕРЕГОВОРОВ}% Разбиение на строки осуществляется командой \\

\author{\firstname{А.~И.}~\surname{Пьяных}}
% Здесь разбиение на строки осуществляется автоматически или командой \\
\email{artem.pyanykh@gmail.com}
\affiliation{%
МГУ им. М.~В.~Ломоносова, ф-т ВМиК
}%

\date{\today} %\today печатает cегодняшнее число

\begin{abstract}
  Рассматривается модификация дискретной многошаговой модели биржевых торгов.
  Два игрока ведут между собой торги рисковыми ценными бумагами (акциями).
  Один из игроков (инсайдер) знает настоящую цену акции, второй знает только её вероятностное распределение.
  На каждом шаге торгов игроки делают целочисленные ставки.
  Игрок, предложивший большую ставку, покупает у второго акцию, причем цена сделки определяется как выпуклая комбинация предложенных ставок с некоторым заданным коэффициентом.
  Получено решение игры бесконечной продолжительности при произвольных значениях параметров: найдены оптимальные стратегии игроков и значение игры.
\end{abstract}

\maketitle

\section{Введение}
\label{sec:intro}

В. Доманским в работе \cite{domansky07} рассмотрена модель многошаговых торгов однотипными акциями, в которой торги ведут между собой два игрока.
Случайная цена акции может принимать два значения ($ 0 $ или $ m $).
Перед началом торгов случайный ход определяет цену акции на весь период торгов.
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй знает, что первый игрок --- инсайдер.
Оба игрока знают вероятность высокой цены акции.
На каждом шаге торогов оба игрока одновременно и независимо назначают некоторую цену за акцию.
Игроки могут делать произвольные целочисленные ставки, причем игрок предложивший большую цену покупает у второго акцию по названной цене. 
Предложенные цены объявляются игрокам в конце каждого хода. 
Игроки помнят предложенные цены на всех предыдущих этапах торгов.
Задачей игроков является максимизация стоимости своего портфеля.

Данная модель сводится к повторяющейся игре с неполной информацией неограниченной продолжительности, как описано в \cite{aumann95-rep}, для которой Доманским получено решение.
Нахождение явного решения для конечных игр остается открытой проблемой.
Для $ n $--шаговых игр в работе \cite{kreps09} В. Крепс получено явное решение при $ m \leq 3 $. 
В работе \cite{sandomirskaya12} М. Сандомирской и В. Доманским найдено явное решение одношаговой игры при произвольном натуральном значении $ m $.

В работе \cite{chatterjee83} Чаттерджи и Самуэльсон рассматривают модель двухстороннего аукциона с неполной информацией.
В торгах участвуют две стороны, покупатель и продавец, которые характеризуются своими резервными ценами $v_b$ и $v_s$ соответственно.
С точки зрения покупателя резервная цена продавца -- это случайная величина $\mathbf{v_s}$, распределенная на отрезке $[\underline{v_s}, \overline{v_s}]$.
Аналогично, с точки зрения продавца резервная цена покупателя -- это случайная величина $\mathbf{v_b}$, распределенная на отрезке $[\underline{v_b}, \overline{v_b}]$.
Правило торгов следующее: покупатель и продавец одновременно называют цены $b$ и $s$ соответственно.
В случае, если $b \geq s$, товар продается по цене $p = \beta b + (1-\beta) s$, где $\beta \in [0, 1]$.

Подобный механизм формирования цены акции можно применить и в данном случае.
Пусть наибольшая ставка задает направление транзакции, в то время как цена сделки равняется выпуклой комбинации предложенных ставок с некоторым заданным коэффициентом $\beta \in [0,1]$.

В работе \cite{domansky07} фактически $\beta = 1$.
Решение задачи при значении $\beta = 1/2$ получено в работе \cite{pyanykh14}.
В данной работе мы рассматриваем обобщение модели на случай произвольного вещественного $\beta \in [0,1]$, и исследуем оптимальные стратегии игроков и их выигрыши в бесконечной игре.

Нужно отметить, что в работе \cite{domansky07} ставки пропорциональны денежной единице, в которой ведутся торги, поэтому все транзакции проводятся в целых числах. 
При вещественном $\beta$ цена сделки перестает быть целочисленной, однако интерпретацию дискретности модели в этой постановке можно оставить неизменной.
Проблему нецелой финальной выплаты размера $a$ можно решить с помощью случайного механизма, который выберет либо выплату размера $[a]$, либо выплату размера $[a] + 1$.
Ожидаемый выигрыш при этом не изменится, но свойство дискретности модели сохранится.

\section{Модель}
\label{sec:model}

Описание модели во многом повторяет описание модели в \cite{pyanykh14}. Мы приводим его здесь в развернутом виде для упрощения изложения.

Два игрока с противоположными интересами имеют деньги и однотипные акции.
Случайная цена акции может принимать либо значение $ m $ в состоянии $ H $, либо $ 0 $ в состоянии $ L $ и определяется на весь период торгов на первом шаге ходом случая.
Первый игрок осведомлен о результате случайного хода, второй игрок знает только вероятность того или иного состояния. 
Второй игрок знает, что первый является инсайдером.
На каждом последующем шаге игроки одновременно предлагают свою цену за одну акцию.
Игрок, назвавший большую цену покупает у другого игрока акцию, по цене равной полусумме предложенных цен.
В случае одинаковых ставок транзакции не происходит.

Данную модель торгов можно рассматривать как повторяющуюся игру с неполной информацией.
Игра задается множеством состояний, каждому состоянию соответствует матричная игра, где матрицу можно рассматривать как матрицу выигрышей первого игрока.

Таким образом мы приходим к следующей формализации рассматриваемой модели.
Множество состояний рынка $ S = \states $. На первом шаге случай выбирает $ s \in S $ с вероятностями $ p(H) = p $ и $ p(L) = (1 - p) $.
После этого на протяжении $ n \leq \infty $ шагов игроки играют в игру $ A^s $.
Соответствующие платежные матрицы задаются следующим образом:
\begin{equation*}
  A^L(i, j) = \begin{cases}
    \alpha i + \beta j, &\, i < j, \\
    0, &\, i = j, \\
    -\beta i - \alpha j, &\, i > j,
  \end{cases}
  \qquad
  A^H(i, j) = \begin{cases}
    \alpha i + \beta j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \beta i - \alpha j, &\, i > j,
  \end{cases}
\end{equation*}
где $\alpha = 1 - \beta$, $\beta \in [0,1]$.

На $ t $-ом шаге первый игрок выбирает ставку $ i_t \in I = \{0, 1, \ldots, m\} $, а второй --- ставку $ j_t \in J = \{0, 1, \ldots, m\} $. 
Выигрыш первого игрока в повторяющейся игре равен $ \sum_{t=1}^n a_{i_t j_t}^s $. 
Второму игроку этот выигрыш становится известным только после окончания игры.
На промежуточных шагах он не имеет точной информации о величинах $ a_{i_t j_t}^s $.

Таким образом, стратегией первого игрока является последовательность ходов
$
  \sigma~=~(\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots),
$
где $\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$, а $\Delta(I)$ --- вероятностное распределение на множестве возможных ставок.
Как и в \cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество всевозможных таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов
$
  \tau~=~(\tau_1, \tau_2, \ldots, \tau_t, \ldots),
$
где $ \tau_t: I^{t-1} \rightarrow \Delta(J) $.
Множество всевозможных стратегий второго игрока обозначим через $\Tau$.
Игру обозначим через $ \generalGame{n}{p} $.

При применении первым игроком смешанной стратегий 
$ \sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n) $, где 
$ 
  \sigma_t~=~(\sigma_t^L, \sigma_t^H), \quad
  \sigma^s_t~=~(\sigma^s_{t, 1}, \ldots, \sigma^s_{t, m}) \in \Delta(I),
$ 
а вторым игроком смешанной стратегии 
$ \tau~=~(\tau_1, \tau_2, \ldots, \tau_n) $, где
$ \tau_t~=~(\tau_{t, 1}, \ldots, \tau_{t, m}) \in \Delta(J) $,
выигрыш первого игрока равен
\begin{equation}
  \label{eq:firstPlayerPayoff}
  \firstPlayerPayoff{n}{p}{\sigma}{\tau} = \sum_{t=1}^n
  \left(
    pA^H(\sigma_t^H, \tau_t) + (1 - p)A^L(\sigma_t^L, \tau_t)
  \right),
\end{equation}
где 
$ 
A^s(\sigma^s_t,\tau_t) = 
    \sum_{i \in I}
        \sum_{j \in J}
            \sigma^s_{t, i} \tau_{t, j} A^s(i, j).
$

Через $\gameValue{n}{p}$ обозначим значение игры $\generalGame{n}{p}$.

\section{Оценки на выигрыш первого игрока}
\label{sec:payoffBounds}

\subsection{Оценка сверху}
\label{sec:-upperBound}

Большая часть построений, используемых для получения оценки сверху, аналогична приведенным в \cite{pyanykh14}.
Изменения коснутся только некоторых обозначений и формулировок утверждений.

Рассмотрим чистую стратегию второго игрока $\tau^k, \, k \in J$:

\begin{align*}
  \tau^k_1 &= k, \\
  \tau^k_t(i_{t-1}, j_{t-1}) &= \begin{cases}
    j_{t-1} - 1, &\, i_{t-1} < j_{t-1},\\
    j_{t-1}, &\, i_{t-1} = j_{t-1},\\
    j_{t-1} + 1, &\, i_{t-1} > j_{t-1}.
  \end{cases}
\end{align*}

По сути эта стратегия представляет собой стратегию подражания инсайдеру.
Доказательство следующего утверждения проводится по индукции.

\begin{proposition}
  \label{proposition:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\infiniteGame{p}$ второй игрок гарантирует себе проигрыш не более
  \begin{align*}
    h_n^L(\tau^k) &= \sum_{t=0}^{n-1}(k - t - \alpha)^+,\\
    h_n^H(\tau^k) &= \sum_{t=0}^{n-1}(m - k - t - \beta)^+,
  \end{align*}
  в состояниях L и H соответственно, где $x^+ = \max(x; 0)$.
\end{proposition}

Очевидно, значения $h_n^L(\tau^k)$ и $h_n^H(\tau^k)$ ограничены сверху по $n$.
Тогда можно ввести следующую функцию:
\begin{multline*}
  \upperBound{p} = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  = \min_{j \in J} \frac{1}{2} \left(
    p (m - j)(m - j + \alpha - \beta) + (1 - p)j(j + \beta - \alpha)
  \right)
\end{multline*}

Функция $\upperBound{p}$ является кусочно-линейной функцией, состоящей из $m+1$ линейных сегментов, и полностью определяется своими значениями в точках
\begin{gather*}
  \
  \upperBound{\frac{k+\beta}{m}} = 1/2 \left(
  (m - (k + \beta))(k + \beta) + \alpha\beta
  \right), \, k = \overline{0, m - 1},\\
  \upperBound{0} = \upperBound{1} = 0.
\end{gather*}

Пусть второй игрок при $p \in \left(\frac{k-\alpha}{m}, \frac{k+\beta}{m}\right]$ применяет $\tau^k, \, k \in \overline{0, m}$. Обозначим эту стратегию через $\tau^*$. Тогда справедлива следующая

\begin{lemma}
  \label{lemma:upperBound} 
  При использовании вторым игроком стратегии $\tau^*$ в игре $\infiniteGame{p}$, выигрыш первого игрока ограничен сверху функцией $\upperBound{p}$, т.е.
  \[
  \max_{\sigma \in \Sigma} 
    \infiniteFirstPlayerPayoff{p}{\sigma}{\tau^*}
  \leq \upperBound{p}.
  \]
\end{lemma}

\subsection{Оценка снизу}
\label{sec:-lowerBound}

Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее $\upperBound{p}$ в игре $\infiniteGame{p}$.

Пусть на определенном шаге игрок применяет 
$
\fGeneral{k}~=~\left(\fGeneral{H}, \fGeneral{L}\right)
$, где 
$\fGeneral{H} = \left(\fGeneral[1,k]{H}, \fGeneral[1,k+1]{H}\right)$,
$\fGeneral{L} = \left(\fGeneral[1,k]{L}, \fGeneral[1,k+1]{L}\right)$ и
$\fGeneral[1,i]{s}$ -- вероятность сделать ставку равную $i$ в состоянии $s \in \states$.
Применяя $\fGeneral{k}$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

Определим следующие параметры: полные вероятности действий $k$ и $k+1$ равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\fGeneral[1,i]{s}$ можной найти по формуле Байеса
\[
\fGeneral[1,i]{s} = \frac{p(s|i)q_i}{p(s)}, \: i = k, k + 1.
\]

Следующее утверждение характеризует $\fGeneral{k}$ с точки зрения гарантированного результата и является обобщением утверждения 4.1 из \cite{pyanykh14}.

\begin{proposition}
  При использовании $\fGeneral{k}$ первый игрок гарантирует себе на первом шаге выигрыш
  \begin{equation}
    \label{eq:lowerPayoffGeneral}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} =
    \begin{cases}
      mp - \beta k - \alpha j - \beta q_{k+1}, &\, j < k,\\
      \left(
        m p(H|k+1) - k - \beta
      \right) q_{k+1}, &\, j = k,\\
      \left(
        k + \beta - m p(H|k)
      \right) q_k, &\, j = k + 1,\\
      \alpha k + \beta j - mp + \alpha q_{k+1}, &\, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}

Данное равенство элементарно следует из (\ref{eq:firstPlayerPayoff}) и определения $\fGeneral{k}$.

Перейдем к обобщению стратегии инсайдера из \cite{pyanykh14} на случай произвольного $\beta$. Рассмотрим на $[0,1]$ множество $P$ точек вида
\[
\pEven[i] = \frac{i}{m}, \, i = \overline{0, m}, \quad
\pOdd[j] = \frac{j + \beta}{m}, \, j = \overline{0, m - 1}.
\]

Для $p = \pEven$ определим через $\fEven$ действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  p(H|k) = \frac{k - 1 + \beta}{m}, \quad p(H|k + 1) = \frac{k + \beta}{m},\\
  q_k = \beta, \quad q_{k+1} = \alpha.
\end{gather*}
Пусть также $\fEven[0] = 0$ и $\fEven[m] = m$ (т.е. если неопределенности нет, первый игрок использует максиминную стратегию в соответствующей матричной игре).

Аналогично для $p = \pOdd$ определим через $\fOdd$ действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  p(H|k) = \frac{k}{m}, \quad p(H|k + 1) = \frac{k + 1}{m},\\
  q_k = \alpha, \quad q_{k+1} = \beta.
\end{gather*}

\begin{proposition}
  При $p \in P$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{\tau}$ выигрыша первого игрока верны оценки
  \begin{align*}
  \min_{\tau \in \Tau}
    \firstPlayerPayoff{1}{\pEven}{\fEven}{\tau} &\geq 0 
  \\
  \min_{\tau \in \Tau}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{\tau} &\geq \alpha\beta.
  \end{align*}
\end{proposition}
Справедливость утверждения устанавливается подстановкой значений параметров $\fEven$ и $\fOdd$ в (\ref{eq:lowerPayoffGeneral}).

Заметим, что если $p \in P$, то при применении инсайдером на первом шаге игры $\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих шагах игры, тем самым определив стратегию $\fOpt$ в игре
$\generalGame{n}{p}, \, p \in P, \, n \in \mathbb{N}$.

Пусть $\lowerBound[n]{p}, \, p \in P$ -- гарантированный выигрыш первого игрока в игре $\generalGame{n}{p}$ при применении стратегии $\fOpt$.
В силу рекурсивной структуры игры $\generalGame{n}{p}$ (см. \cite{domansky07}) для $\lowerBound[n]{p}$ справедливы формулы
\begin{gather}
  \label{eq:lowerBound:recurrence:function}
  \lowerBound[n]{\frac{k + \beta}{m}} = \alpha\beta + 
    \alpha\lowerBound[n-1]{\frac{k}{m}} +
    \beta\lowerBound[n-1]{\frac{k + 1}{m}}\\
  %
  \lowerBound[n]{\frac{k}{m}} =
    \beta\lowerBound[n-1]{\frac{k - 1 + \beta}{m}} +
    \alpha\lowerBound[n-1]{\frac{k + \beta}{m}}\\
  %
  \lowerBound[n]{0} = \lowerBound[n]{1} = 0.
\end{gather}

Так как $\lowerBound[n]{p}$ не убывает по $n$ и ограничена сверху, устремив $n$ к бесконечности, получим нижнюю оценку $\lowerBound{p}$ выигрыша первого игрока в игре $\infiniteGame{p}, \, p \in P$.

Введем следующие обозначения:
\[
L_{2k} = \lowerBound{k/m}, \, k \in \overline{0,m}, \:%
L_{2k+1} = \lowerBound{(k+\beta)/m)}, \, k \in \overline{0,m-1}.
\]
Тогда справедливы формулы
\begin{equation}
  \label{eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \alpha\beta + \alpha L_{2k} + \beta L_{2(k+1)}, \, k \in \overline{0, m-1},\\
    L_{2k} = \beta L_{2k-1} + \alpha L_{2k+1}, \, k \in \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

Введем матрицу $ B \in \mathbb{R}^{(2m-1)\times(2m-1)} $ и вектор-столбец $ b \in \mathbb{R}^{2m-1} $ следующим образом:
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\beta  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\beta & 1       & -\alpha & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\alpha & 1       & -\beta & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\beta & 1       & -\alpha \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\alpha & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \alpha\beta \\
      0           \\
      \alpha\beta \\
      \cdots      \\
      0           \\
      \alpha\beta
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{eq:lowerRecurrence}) перепишем в следующем виде: 
\[
BL = B, L_0 = L_{2m} = 0
\]
где 
$L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
M = \left(\begin{array}{ccccccc}
c_1 & b_1 & 0 & \cdots & 0 & 0 & 0 \\
a_2 & c_2 & b_2 & \cdots & 0 & 0 & 0 \\
\hdotsfor{7} \\
0 & 0 & 0 & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
0 & 0 & 0 & \cdots & 0 & a_n & c_n
\end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для прогоночных коэффициентов и переменных (см. \cite{samarsky89-num}):
\begin{equation}
  \label{eq:tridiagonal:formulas}
  \begin{gathered}
    x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1}, \quad
    x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
    % 
    \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2, n-1}, \quad
    \gamma_2 = -\frac{b_1}{c_1}, \\
    % 
    \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i = \overline{2, n-1}, \quad
    \delta_2 = \frac{f_1}{c_1}.
  \end{gathered}
\end{equation}

\begin{proposition}
  \label{proposition:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими формулами:
  \begin{multline*}
    \gamma_{2k} = \frac{\beta+k-1}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\beta}, \\
    \delta_{2k} = \frac{\alpha(k-1+2\beta)}{2}, \,
    \delta_{2k+1} = \frac{k\beta(k-1+2\beta)}{2(k+\beta)}, \quad k \in \overline{1,m-1}.
  \end{multline*}
\end{proposition}
Справедливость данного утверждения устанавливается доказательством по индукции.

Заметим, что $L_{2k-1} = \gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} + \beta_{2k}$.
Подстановкой $\upperBound{\frac{k+\beta}{m}}$ вместо $L_{2k+1}$ это равенство обращается в тождество, тем самым доказывая

\begin{proposition}
  \label{proposition:lower:recurrence-solution}
  Решение системы (\ref{eq:lowerRecurrence}) дается следующими формулами:
  \begin{gather*}
    L_{2k+1} = 1/2((m - (k + \beta))(k + \beta) + \alpha\beta), \, k = \overline{0, m-1}, \\
    L_{2k} = 1/2 k (m-k), \, k = \overline{0,m}.
  \end{gather*}
\end{proposition}

Таким образом мы определили функцию $\lowerBound{p}$ при $p \in P$.

\begin{proposition}
  \label{proposition:first:combination:step}
  При $\lambda \in (0, 1)$ и $\beta \geq \frac{1}{2}$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{\tau}$ выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{\tau \in \Tau}
      \firstPlayerPayoff{1}{%
        \lambda \pEven + (1-\lambda) \pOdd}{%
        \lambda \fEven + (1-\lambda) \fOdd}{%
        \tau}
      &\geq \alpha \beta (1-\lambda)\\
      %
    \min_{\tau \in \Tau}
      \firstPlayerPayoff{1}{%
        \lambda \pOdd + (1-\lambda) \pEven[k+1]}{%
        \lambda \fOdd + (1-\lambda) \fEven[k+1]}{%
        \tau}
      &\geq \alpha \beta \lambda.
  \end{align*}
\end{proposition}
Данные неравенства можно доказать, воспользовавшись равенством (\ref{eq:lowerPayoffGeneral}) и линейностью $\firstPlayerPayoff{1}{p}{\sigma}{\tau}$ по $\sigma$.

\begin{proposition}
  \label{proposition:first:combination:game}
  При $\lambda \in (0, 1)$ и $\beta \geq \frac{1}{2}$ для гарантированного выигрыша первого игрока в игре $\infiniteGame{p}$ справедливо
  \begin{align*}
    \lowerBound{\lambda \pEven + (1-\lambda) \pOdd} &= 
      \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}\\
    \lowerBound{\lambda \pOdd + (1-\lambda) \pEven[k+1]} &=
      \lambda \lowerBound{\pOdd} + (1-\lambda) \lowerBound{\pEven}.
  \end{align*}
\end{proposition}
\begin{proof}
  Покажем, что линейная комбинация соответствующих крайних стратегий дает необходимый результат.

  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1], \, k = \overline{0, m - 2}$.
  В этом случае при использовании $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ первый игрок рандомизирует между ставками $k, k + 1, k + 2$ с параметрами
  \begin{gather*}
    q_k = \lambda\alpha, \, q_{k+1} = \beta, \, q_{k+2} = (1-\lambda)\alpha,\\
    p(H|k) = \pEven, \, p(H|k+1) = \lambda \pEven[k+1] + (1-\lambda) \pOdd, \, p(H|k+2) = \pOdd[k+1].
  \end{gather*}
  
  Тогда по аналогии с (\ref{eq:lowerBound:recurrence:function}) выписывается рекуррентная формула для $\lowerBound{p}$
  \begin{equation}
    \label{eq:first:combination:game:1}
    \lowerBound{p} = \alpha \beta \lambda +
      \lambda \alpha \lowerBound{\pEven} +
      (1-\lambda) \alpha \lowerBound{\pOdd[k+1]} +
      \beta \lowerBound{(1-\lambda) \pOdd + \lambda \pEven[k+1]}.
  \end{equation}
  Так как $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in (\pOdd, \pEven[k+1])$, то для $\lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]}$ справедливо аналогичное представление.
  Приведя подобные в (\ref{eq:first:combination:game:1}), получим
  \begin{multline}
    \label{eq:first:combination:game:2}
    \lowerBound{p} = \frac{1}{1-\beta^2} \left(
      \alpha\beta\lambda + \alpha\lambda\lowerBound{\pEven} + (1-\lambda)\lowerBound{\pOdd[k+1]} + \\
      %
      + \beta\left(
          \alpha\beta(1-\lambda) + (1-\lambda)\alpha\lowerBound{\pEven} + \lambda\alpha\lowerBound{\pOdd[k+1]}
        \right)
      \right) = \\
      %
      = \frac{1}{2}\left(
        (k + 1)(m - k - 1) + \alpha\lambda(2k - m + 2\beta + 1)
      \right) = \\
      = \lambda\lowerBound{\pOdd} + (1-\lambda)\lowerBound{\pEven[k+1]}.
  \end{multline}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd, \, k = \overline{1, m - 1}$.
  В этом случае при использовании $\lambda\fEven + (1-~\lambda)\fOdd$ первый игрок рандомизирует между ставками $k$ и $k+1$ с параметрами
  \begin{gather*}
    q_k = \lambda\beta + (1-\lambda)(1-\beta), \:
    p(H|k) = \frac{\lambda\beta}{q_k}\pOdd[k-1] +
      \frac{(1-\lambda)(1-\beta)}{q_k} \pEven,\\
    q_{k+1} = \lambda(1-\beta) + (1-\lambda)\beta, \:
    p(H|k+1) = \frac{\lambda(1-\beta)}{q_{k+1}}\pOdd[k] +
      \frac{(1-\lambda)\beta}{q_{k+1}}\pEven[k+1].
  \end{gather*}
\end{proof}

%
% Список литературы
%
\nocite{*}
\bibliography{paper}
%
\newpage
%
% Для статей на русском языке далее следуют
% на английском языке название статьи, список авторов и краткая аннотация.
%
\selectlanguage{english}
\begin{center}
\large \bfseries \MakeTextUppercase{%
  Multistage bidding model with bargaining
}
\end{center}
%
\begin{center}
\bfseries A.~Pyanykh
\end{center}
%
\begin{center}
\begin{minipage}{\textwidth - 2cm}
  \small%
  This paper is concerned with a modification of a discreete multistage bidding model.
  Bidding takes place between two players for one unit of a risky asset.
  The first player (an insider) knows the real price of the asset, while the second knows only a probability distribution over the price.
  At each stage of the bidding players make integral bids.
  The higher bid wins and one unit of the asset is transacted to the winning player, wherein the price of the transaction equals to a convex combination of bids with some arbitrary coefficient.
  This model is reduced to a repeated game with incomplete information. The solution for the infinite game is found including optimal strategies for both players and the value of the game.
\end{minipage}
\end{center}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Character code reference %%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%     Upper case russian letters (CP866): АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ   %                                                                       %
%     Lower case russian letters (CP866): абвгдеёжзийклмнопрстуфхцчшщъыьэюя   %
%                     Upper case letters: ABCDEFGHIJKLMNOPQRSTUVWXYZ          %
%                     Lower case letters: abcdefghijklmnopqrstuvwxyz          %
%                                   Digits: 0123456789                        %
% Square, curly, angle braces, parentheses: [] {} <> ()                       %
%                Backslash, slash, solidus: \ / |                             %
%       Period, interrogative, exclamation: . ? !                             %
%                 Comma, colon, semi-colon: , : ;                             %
%          Underscore, hyphen, equals sign: _ - =                             %
%             Quotes (left, right, double): ` ' "                             %
%     Commercial-at, hash, dollar, percent: @ # $ %                           %
%  Ampersand, asterisk, plus, caret, tilde: & * +   ^                         %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ****** End of file apssampr.tex ******
