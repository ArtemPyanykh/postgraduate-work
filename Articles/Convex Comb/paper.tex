% -*- coding: cp1251 -*- %
\documentclass[12pt, a4paper]{article}
\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}

\usepackage[centertags]{amsmath}
\usepackage{amsthm,amsfonts,amssymb}
\usepackage{indentfirst}
%-------------------------------------------------------------------------------
\frenchspacing
\parindent=0.6cm
\parskip=2pt
\mathsurround=1pt
%
\makeatletter
\renewcommand{\@biblabel}[1]{#1.}
\makeatother
%
\topskip=0mm
\headsep=0mm
\topmargin=0mm
\headheight=0mm
\textwidth=165mm
\textheight=240mm
\oddsidemargin=0mm

\renewcommand{\baselinestretch}{1.3}
%--------------------------------------------------------------------------

\newtheorem{lemma}{\indent Лемма}
\newtheorem{theorem}{\indent Теорема}
\newtheorem{proposition}{Утверждение}
\newtheorem{remark}{Замечание}
\def\proof{{\indent Доказательство.}}

%%%%%%%%%%   Custom commands   %%%%%%%%%%%%%%
\newcommand{\Tau}{%
\mathrm{T}
}

\newcommand{\states}{%
\left\{H, L\right\}
}

\newcommand{\generalGame}[2]{%
G_{#1}^{m, \beta}\left({#2}\right)%
}

\newcommand{\infiniteGame}[1]{%
G_{\infty}^{m, \beta}\left({#1}\right)%
}

\newcommand{\firstPlayerPayoff}[4]{%
K_{#1}^{m,\beta}\left({#2}, {#3}, {#4}\right)%
}

\newcommand{\infiniteFirstPlayerPayoff}[3]{%
K_{\infty}^{m,\beta}\left({#1}, {#2}, {#3}\right)%
}

\newcommand{\gameValue}[2]{%
V_{#1}^{m,\beta}\left({#2}\right)%
}

\newcommand{\infiniteGameValue}[1]{%
V_{\infty}^{m,\beta}\left({#1}\right)%
}

\newcommand{\symm}[1]{%
\overline{#1}%
}

\newcommand{\symmGameExpression}[2][\infty]{%
G_{#1}^{m, 1-\beta}\left({#2}\right)%
}

\newcommand{\upperBound}[1]{%
H_{\infty}^{m,\beta}\left({#1}\right)%
}

\newcommand{\fGeneral}[2][1]{%
\sigma_{#1}^{#2}%
}

\newcommand{\pEven}[1][k]{%
p^0_{#1}%
}

\newcommand{\pOdd}[1][k]{%
p^{\beta}_{#1}%
}

\newcommand{\fEven}[1][k]{%
\phi^0_{#1}%
}

\newcommand{\fOdd}[1][k]{%
\phi^{\beta}_{#1}%
}

\newcommand{\fOpt}{\sigma^*}

\newcommand{\lowerBound}[2][\infty]{%
L_{#1}^{m,\beta}\left({#2}\right)%
}
%%%%%%%%%% End custom commands %%%%%%%%%%%%%%

\begin{document}

\noindent УДК 519.832.2
\medskip

{\bfseries
А.\,И. Пьяных\footnote{Факультет ВМК МГУ, асп.,
                       E--mail: artem.pyanykh@gmail.com},
\medskip

МОДЕЛЬ БИРЖЕВЫХ ТОРГОВ С ИНСАЙДЕРОМ \\
\indent С ЭЛЕМЕНТАМИ ПЕРЕГОВОРОВ

\begin{quotation}{\footnotesize
  Рассматривается модификация дискретной многошаговой модели биржевых торгов.
  Два игрока ведут между собой торги рисковыми ценными бумагами (акциями).
  Один из игроков (инсайдер) знает настоящую цену акции, второй знает только ее вероятностное распределение.
  На каждом шаге торгов игроки делают целочисленные ставки.
  Игрок, предложивший большую ставку, покупает у второго акцию, причем цена сделки определяется как выпуклая комбинация предложенных ставок с некоторым заданным коэффициентом.
  Получено решение игры бесконечной продолжительности при произвольных значениях параметров: найдены оптимальные стратегии игроков и значение игры.
   \\
   \indent\textit{Ключевые слова}: многошаговые игры, асимметричная информация, повторяющиеся игры с неполной информацией.}
\end{quotation}
\medskip

\section{Введение}
\label{sec:intro}

В. Доманским в работе \cite{domansky07} рассмотрена модель многошаговых торгов однотипными акциями, в которой торги ведут между собой два игрока.
Случайная цена акции может принимать два значения ($ 0 $ или $ m $).
Перед началом торгов случайный ход определяет цену акции на весь период торгов.
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй знает, что первый игрок --- инсайдер.
Оба игрока знают вероятность высокой цены акции.
На каждом шаге торгов оба игрока одновременно и независимо назначают некоторую цену за акцию.
Игроки могут делать произвольные целочисленные ставки, причем игрок предложивший большую цену покупает у второго акцию по названной цене. 
Предложенные цены объявляются игрокам в конце каждого хода. 
Игроки помнят предложенные цены на всех предыдущих этапах торгов.
Задачей игроков является максимизация стоимости своего портфеля.

Данная модель сводится к повторяющейся игре с неполной информацией неограниченной продолжительности, как описано в \cite{aumann95-rep}, для которой Доманским получено решение.
Нахождение явного решения для конечных игр остается открытой проблемой.
Для $ n $--шаговых игр в работе \cite{kreps09} В. Крепс получено явное решение при $ m \leq 3 $. 
В работе \cite{sandomirskaya12} М. Сандомирской и В. Доманским найдено явное решение одношаговой игры при произвольном натуральном значении $ m $.

В работе \cite{chatterjee83} Чаттерджи и Самуэльсон рассматривают модель двухстороннего аукциона с неполной информацией.
В торгах участвуют две стороны, покупатель и продавец, которые характеризуются своими резервными ценами $v_b$ и $v_s$ соответственно.
С точки зрения покупателя резервная цена продавца -- это случайная величина $\mathbf{v_s}$, распределенная на отрезке $[\underline{v_s}, \overline{v_s}]$.
Аналогично, с точки зрения продавца резервная цена покупателя -- это случайная величина $\mathbf{v_b}$, распределенная на отрезке $[\underline{v_b}, \overline{v_b}]$.
Правило торгов следующее: покупатель и продавец одновременно называют цены $b$ и $s$ соответственно.
В случае, если $b \geq s$, товар продается по цене $p = \beta b + (1-\beta) s$, где $\beta \in [0, 1]$.

Подобный механизм формирования цены акции можно применить и в данном случае.
Пусть наибольшая ставка задает направление транзакции, в то время как цена сделки равняется выпуклой комбинации предложенных ставок с некоторым заданным коэффициентом $\beta \in [0,1]$.

В работе \cite{domansky07} фактически $\beta = 1$.
Решение задачи при значении $\beta = 1/2$ получено в работе \cite{pyanykh14}.
В данной работе мы рассматриваем обобщение модели на случай произвольного вещественного $\beta \in [0,1]$, и исследуем оптимальные стратегии игроков и их выигрыши в бесконечной игре.

Нужно отметить, что в работе \cite{domansky07} ставки пропорциональны денежной единице, в которой ведутся торги, поэтому все транзакции проводятся в целых числах. 
При вещественном $\beta$ цена сделки перестает быть целочисленной, однако интерпретацию дискретности модели в этой постановке можно оставить неизменной.
Проблему нецелой финальной выплаты размера $a$ можно решить с помощью случайного механизма, который выберет либо выплату размера $[a]$, либо выплату размера $[a] + 1$.
Ожидаемый выигрыш при этом не изменится, но свойство дискретности модели сохранится.

\section{Модель}
\label{sec:model}

Описание модели во многом повторяет описание модели в \cite{pyanykh14}. Мы приводим его здесь в развернутом виде для упрощения изложения.

Два игрока с противоположными интересами имеют деньги и однотипные акции.
Случайная цена акции может принимать либо значение $ m $ в состоянии $ H $, либо $ 0 $ в состоянии $ L $ и определяется на весь период торгов на первом шаге ходом случая.
Первый игрок осведомлен о результате случайного хода, второй игрок знает только вероятность того или иного состояния. 
Второй игрок знает, что первый является инсайдером.
На каждом последующем шаге игроки одновременно предлагают свою цену за одну акцию.
Игрок, назвавший большую цену покупает у другого игрока акцию, по цене равной полусумме предложенных цен.
В случае одинаковых ставок транзакции не происходит.

Данную модель торгов можно рассматривать как повторяющуюся игру с неполной информацией.
Игра задается множеством состояний, каждому состоянию соответствует матричная игра, где матрицу можно рассматривать как матрицу выигрышей первого игрока.

Таким образом мы приходим к следующей формализации рассматриваемой модели.
Множество состояний рынка $ S = \states $. На первом шаге случай выбирает $ s \in S $ с вероятностями $ p(H) = p $ и $ p(L) = (1 - p) $.
После этого на протяжении $ n \leq \infty $ шагов игроки играют в игру $ A^s $.
Соответствующие платежные матрицы задаются следующим образом:
\begin{equation*}
  A^{L,\beta}(i, j) = \begin{cases}
    \alpha i + \beta j, &\, i < j, \\
    0, &\, i = j, \\
    -\beta i - \alpha j, &\, i > j,
  \end{cases}
  \qquad
  A^{H,\beta}(i, j) = \begin{cases}
    \alpha i + \beta j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \beta i - \alpha j, &\, i > j,
  \end{cases}
\end{equation*}
где $\alpha = 1 - \beta$, $\beta \in [0,1]$.

На $ t $-ом шаге первый игрок выбирает ставку $ i_t \in I = \{0, 1, \ldots, m\} $, а второй --- ставку $ j_t \in J = \{0, 1, \ldots, m\} $. 
Выигрыш первого игрока в повторяющейся игре равен $ \sum_{t=1}^n a_{i_t j_t}^{s,\beta} $. 
Второму игроку этот выигрыш становится известным только после окончания игры.
На промежуточных шагах он не имеет точной информации о величинах $ a_{i_t j_t}^{s,\beta} $.

Таким образом, стратегией первого игрока является последовательность ходов
$
  \sigma~=~(\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots),
$
где $\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$, а $\Delta(I)$ --- вероятностное распределение на множестве возможных ставок.
Как и в \cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество всевозможных таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов
$
  \tau~=~(\tau_1, \tau_2, \ldots, \tau_t, \ldots),
$
где $ \tau_t: I^{t-1} \rightarrow \Delta(J) $.
Множество всевозможных стратегий второго игрока обозначим через $\Tau$.
Игру обозначим через $ \generalGame{n}{p} $.

При применении первым игроком смешанной стратегий 
$ \sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n) $, где 
$ 
  \sigma_t~=~(\sigma_t^L, \sigma_t^H), \quad
  \sigma^s_t~=~(\sigma^s_{t, 0}, \ldots, \sigma^s_{t, m}) \in \Delta(I),
$ 
а вторым игроком смешанной стратегии 
$ \tau~=~(\tau_1, \tau_2, \ldots, \tau_n) $, где
$ \tau_t~=~(\tau_{t, 0}, \ldots, \tau_{t, m}) \in \Delta(J) $,
выигрыш первого игрока равен
\begin{equation}
  \label{eq:firstPlayerPayoff}
  \firstPlayerPayoff{n}{p}{\sigma}{\tau} = \sum_{t=1}^n
  \left(
    pA^{H,\beta}(\sigma_t^H, \tau_t) + (1 - p)A^{L,\beta}(\sigma_t^L, \tau_t)
  \right),
\end{equation}
где 
$ 
A^{s,\beta}(\sigma^s_t,\tau_t) = 
    \sum_{i \in I}
        \sum_{j \in J}
            \sigma^s_{t, i} \tau_{t, j} A^{s,\beta}(i, j).
$

Через $\gameValue{n}{p}$ обозначим значение игры $\generalGame{n}{p}$.

Заметим, что $A^{L,\beta}(i,j) = A^{H,1-\beta}(m-i,m-j), A^{H,\beta}(i,j) = A^{L,1-\beta}(m-i,m-j)$.
Определим симметричные стратегии игроков
\begin{gather*}
  \symm{\sigma_t} = (\symm{\sigma^H_t}, \symm{\sigma^L}), \: \symm{\sigma^s_t} = (\sigma^s_{t,m},\ldots,\sigma^s_{t,0}) \in \Delta(I),\\
  \symm{\tau_t} = (\tau_{t,m},\ldots,\tau_{t,0}) \in \Delta(J),
\end{gather*}
и симметричную игру $\symm{\generalGame{n}{p}} = \symmGameExpression[n]{1-p}$.
Легко видеть, что выигрыши игроков в симметричных играх при использовании симметричных стратегий совпадают.

\section{Оценки на выигрыш первого игрока}
\label{sec:payoffBounds}

\subsection{Оценка сверху}
\label{sec:-upperBound}

Большая часть построений, используемых для получения оценки сверху, аналогична приведенным в \cite{pyanykh14}.
Изменения коснутся только некоторых обозначений и формулировок утверждений.

Рассмотрим чистую стратегию второго игрока $\tau^k, \, k \in J$:

\begin{align*}
  \tau^k_1 &= k, \\
  \tau^k_t(i_{t-1}, j_{t-1}) &= \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\end{align*}

По сути эта стратегия представляет собой стратегию подражания инсайдеру.
Доказательство следующего утверждения проводится по индукции.

\begin{proposition}
  \label{proposition:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\infiniteGame{p}$ второй игрок гарантирует себе проигрыш не более
  \begin{align*}
    h_n^L(\tau^k) &= \sum_{t=0}^{n-1}(k - t - \alpha)^+,\\
    h_n^H(\tau^k) &= \sum_{t=0}^{n-1}(m - k - t - \beta)^+,
  \end{align*}
  в состояниях L и H соответственно, где $x^+ = \max(x; 0)$.
\end{proposition}

Очевидно, значения $h_n^L(\tau^k)$ и $h_n^H(\tau^k)$ монотонны и ограничены сверху по $n$.
Тогда можно ввести следующую функцию:
\begin{multline*}
  \upperBound{p} = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  %
  = \min_{j \in J} \frac{1}{2} \left(
    p (m - j)(m - j + \alpha - \beta) + (1 - p)j(j + \beta - \alpha)
  \right).
\end{multline*}

Функция $\upperBound{p}$ является кусочно-линейной функцией, состоящей из $m+1$ линейных сегментов, и полностью определяется своими значениями в точках
\begin{gather*}
  \upperBound{\frac{k+\beta}{m}} = \frac{1}{2} \left(
  (m - (k + \beta))(k + \beta) + \alpha\beta
  \right), \, k = \overline{0, m - 1},\\
  \upperBound{0} = \upperBound{1} = 0.
\end{gather*}

Пусть второй игрок при $p \in \left(\frac{k-\alpha}{m}, \frac{k+\beta}{m}\right]$ применяет $\tau^k, \, k \in \overline{0, m}$. Обозначим эту стратегию через $\tau^*$. Тогда справедлива следующая

\begin{lemma}
  \label{lemma:upperBound} 
  При использовании вторым игроком стратегии $\tau^*$ в игре $\infiniteGame{p}$, выигрыш первого игрока ограничен сверху функцией $\upperBound{p}$, т.е.
  \[
  \max_{\sigma \in \Sigma} 
    \infiniteFirstPlayerPayoff{p}{\sigma}{\tau^*}
  \leq \upperBound{p}.
  \]
\end{lemma}

\subsection{Оценка снизу}
\label{sec:-lowerBound}

Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее $\upperBound{p}$ в игре $\infiniteGame{p}$.

Пусть на определенном шаге игрок применяет 
$
\fGeneral{k}~=~\left(\fGeneral{H}, \fGeneral{L}\right)
$, где 
$\fGeneral{H} = \left(\fGeneral[1,k]{H}, \fGeneral[1,k+1]{H}\right)$,
$\fGeneral{L} = \left(\fGeneral[1,k]{L}, \fGeneral[1,k+1]{L}\right)$ и
$\fGeneral[1,i]{s}$ -- вероятность сделать ставку равную $i$ в состоянии $s \in \states$.
Применяя $\fGeneral{k}$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

Определим следующие параметры: полные вероятности действий $k$ и $k+1$ равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\fGeneral[1,i]{s}$ можно найти по формуле Байеса
\[
\fGeneral[1,i]{s} = \frac{p(s|i)q_i}{p(s)}, \: i = k, k + 1.
\]

Следующее утверждение характеризует $\fGeneral{k}$ с точки зрения гарантированного результата и является обобщением утверждения 4.1 из \cite{pyanykh14}.

\begin{proposition}
  При использовании $\fGeneral{k}$ первый игрок гарантирует себе на первом шаге выигрыш
  \begin{equation}
    \label{eq:lowerPayoffGeneral}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} =
    \begin{cases}
      mp - \beta k - \alpha j - \beta q_{k+1},      & \, j < k,     \\
      \left(m p(H|k+1) - k - \beta \right) q_{k+1}, & \, j = k,     \\
      \left(k + \beta - m p(H|k) \right) q_k,       & \, j = k + 1, \\
      \alpha k + \beta j - mp + \alpha q_{k+1},     & \, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}

Данное равенство элементарно следует из (\ref{eq:firstPlayerPayoff}) и определения $\fGeneral{k}$.

Перейдем к обобщению стратегии инсайдера из \cite{pyanykh14} на случай произвольного $\beta$. Рассмотрим на $[0,1]$ множество $P$ точек вида
\[
\pEven[i] = \frac{i}{m}, \, i = \overline{0, m}, \quad
\pOdd[j] = \frac{j + \beta}{m}, \, j = \overline{0, m - 1}.
\]

Для $p = \pEven$ определим через $\fEven$ действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  p(H|k) = \frac{k - 1 + \beta}{m}, \quad p(H|k + 1) = \frac{k + \beta}{m},\\
  q_k = \beta, \quad q_{k+1} = \alpha.
\end{gather*}
Пусть также $\fEven[0] = 0$ и $\fEven[m] = m$ (т.е. если неопределенности нет, первый игрок использует максиминную стратегию в соответствующей матричной игре).

Аналогично для $p = \pOdd$ определим через $\fOdd$ действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  p(H|k) = \frac{k}{m}, \quad p(H|k + 1) = \frac{k + 1}{m},\\
  q_k = \alpha, \quad q_{k+1} = \beta.
\end{gather*}

\begin{proposition}
  При $p \in P$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{\tau}$ выигрыша первого игрока верны оценки
  \begin{align*}
  \min_{\tau \in \Tau}
    \firstPlayerPayoff{1}{\pEven}{\fEven}{\tau} &\geq 0 
  \\
  \min_{\tau \in \Tau}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{\tau} &\geq \alpha\beta.
  \end{align*}
\end{proposition}
Справедливость утверждения устанавливается подстановкой значений параметров $\fEven$ и $\fOdd$ в (\ref{eq:lowerPayoffGeneral}).

Заметим, что если $p \in P$, то при применении инсайдером на первом шаге игры $\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих шагах игры, тем самым определив стратегию $\fOpt$ в игре
$\generalGame{n}{p}, \, p \in P, \, n \in \mathbb{N}$.

Пусть $\lowerBound[n]{p}, \, p \in P$ -- гарантированный выигрыш первого игрока в игре $\generalGame{n}{p}$ при применении стратегии $\fOpt$.
В силу рекурсивной структуры игры $\generalGame{n}{p}$ (см. \cite{domansky07}) для $\lowerBound[n]{p}$ справедливы формулы
\begin{gather}
  \label{eq:lowerBound:recurrence:function}
  \lowerBound[n]{\frac{k + \beta}{m}} = \alpha\beta + 
    \alpha\lowerBound[n-1]{\frac{k}{m}} +
    \beta\lowerBound[n-1]{\frac{k + 1}{m}}\\
  %
  \lowerBound[n]{\frac{k}{m}} =
    \beta\lowerBound[n-1]{\frac{k - 1 + \beta}{m}} +
    \alpha\lowerBound[n-1]{\frac{k + \beta}{m}}\\
  %
  \lowerBound[n]{0} = \lowerBound[n]{1} = 0.
\end{gather}

Так как $\lowerBound[n]{p}$ не убывает по $n$ и ограничена сверху, устремив $n$ к бесконечности, получим нижнюю оценку $\lowerBound{p}$ выигрыша первого игрока в игре $\infiniteGame{p}, \, p \in P$.

Введем следующие обозначения:
\[
L_{2k} = \lowerBound{k/m}, \, k \in \overline{0,m}, \:%
L_{2k+1} = \lowerBound{(k+\beta)/m)}, \, k \in \overline{0,m-1}.
\]
Тогда справедливы формулы
\begin{equation}
  \label{eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \alpha\beta + \alpha L_{2k} + \beta L_{2(k+1)}, \, k \in \overline{0, m-1},\\
    L_{2k} = \beta L_{2k-1} + \alpha L_{2k+1}, \, k \in \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

Введем матрицу $ B \in \mathbb{R}^{(2m-1)\times(2m-1)} $ и вектор-столбец $ b \in \mathbb{R}^{2m-1} $ следующим образом:
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\beta  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\beta & 1       & -\alpha & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\alpha & 1       & -\beta & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\beta & 1       & -\alpha \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\alpha & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \alpha\beta \\
      0           \\
      \alpha\beta \\
      \cdots      \\
      0           \\
      \alpha\beta
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{eq:lowerRecurrence}) перепишем в следующем виде: 
\[
BL = B, L_0 = L_{2m} = 0
\]
где 
$L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
M = \left(\begin{array}{ccccccc}
c_1 & b_1 & 0   & \cdots & 0       & 0       & 0       \\
a_2 & c_2 & b_2 & \cdots & 0       & 0       & 0       \\
\hdotsfor{7}                                           \\
0   & 0   & 0   & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
0   & 0   & 0   & \cdots & 0       & a_n     & c_n
\end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для прогоночных коэффициентов и переменных (см. \cite{samarsky89-num}):
\begin{equation}
  \label{eq:tridiagonal:formulas}
  \begin{gathered}
    x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1}, \quad
    x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
    % 
    \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2, n-1}, \quad
    \gamma_2 = -\frac{b_1}{c_1}, \\
    % 
    \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i = \overline{2, n-1}, \quad
    \delta_2 = \frac{f_1}{c_1}.
  \end{gathered}
\end{equation}

\begin{proposition}
  \label{proposition:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими формулами:
  \begin{multline*}
    \gamma_{2k} = \frac{\beta+k-1}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\beta}, \\
    \delta_{2k} = \frac{\alpha(k-1+2\beta)}{2}, \,
    \delta_{2k+1} = \frac{k\beta(k-1+2\beta)}{2(k+\beta)}, \quad k \in \overline{1,m-1}.
  \end{multline*}
\end{proposition}
Справедливость данного утверждения устанавливается доказательством по индукции.

Заметим, что $L_{2k-1} = \gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} + \beta_{2k}$.
Подстановкой $\upperBound{\frac{k+\beta}{m}}$ вместо $L_{2k+1}$ это равенство обращается в тождество, тем самым доказывая

\begin{proposition}
  \label{proposition:lower:recurrence-solution}
  Решение системы (\ref{eq:lowerRecurrence}) дается следующими формулами:
  \begin{gather*}
    L_{2k+1} = 1/2((m - (k + \beta))(k + \beta) + \alpha\beta), \, k = \overline{0, m-1}, \\
    L_{2k} = 1/2 k (m-k), \, k = \overline{0,m}.
  \end{gather*}
\end{proposition}

Тем самым мы определили функцию $\lowerBound{p}$ при $p \in P$.
Для $p \in [0, 1] \setminus P$ стратегия инсайдера основана на применении линейной комбинации стратегий для крайних точек интервала, в котором находится $p$.

\begin{proposition}
  \label{proposition:first:combination:step}
  При $\lambda \in (0, 1), \, \beta \geq 1/2, \, k = \overline{0, m-1}$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{\tau}$ выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{\tau \in \Tau}
      \firstPlayerPayoff{1}{%
        \lambda \pEven + (1-\lambda) \pOdd}{%
        \lambda \fEven + (1-\lambda) \fOdd}{%
        \tau}
      &\geq \alpha \beta (1-\lambda), \\
      %
    \min_{\tau \in \Tau}
      \firstPlayerPayoff{1}{%
        \lambda \pOdd + (1-\lambda) \pEven[k+1]}{%
        \lambda \fOdd + (1-\lambda) \fEven[k+1]}{%
        \tau}
      &\geq \alpha \beta \lambda.
  \end{align*}
\end{proposition}
Данные неравенства можно доказать, воспользовавшись равенством (\ref{eq:lowerPayoffGeneral}) и линейностью $\firstPlayerPayoff{1}{p}{\sigma}{\tau}$ по $\sigma$.

\begin{proposition}
  \label{proposition:first:combination:game}
  При $\lambda \in (0, 1), \, \beta \geq 1/2, \, k = \overline{0, m-1}$ для гарантированного выигрыша первого игрока в игре $\infiniteGame{p}$ справедливо
  \begin{align*}
    \lowerBound{\lambda \pEven + (1-\lambda) \pOdd}      & = 
      \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}, \\
    \lowerBound{\lambda \pOdd + (1-\lambda) \pEven[k+1]} & =
      \lambda \lowerBound{\pOdd} + (1-\lambda) \lowerBound{\pEven}.
  \end{align*}
\end{proposition}
\begin{proof}
  Покажем, что линейная комбинация соответствующих крайних стратегий дает необходимый результат.

  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1], \, k = \overline{0, m - 2}$.
  В этом случае при использовании $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ первый игрок рандомизирует между ставками $k, k + 1, k + 2$ с параметрами
  \begin{gather*}
    q_k = \lambda\alpha, \, q_{k+1} = \beta, \, q_{k+2} = (1-\lambda)\alpha,\\
    p(H|k) = \pEven, \, p(H|k+1) = \lambda \pEven[k+1] + (1-\lambda) \pOdd, \, p(H|k+2) = \pOdd[k+1].
  \end{gather*}
  
  Тогда по аналогии с (\ref{eq:lowerBound:recurrence:function}) выписывается рекуррентная формула для $\lowerBound{p}$
  \begin{equation}
    \label{eq:first:combination:game:1}
    \lowerBound{p} = \alpha \beta \lambda +
      \lambda \alpha \lowerBound{\pEven} +
      (1-\lambda) \alpha \lowerBound{\pOdd[k+1]} +
      \beta \lowerBound{(1-\lambda) \pOdd + \lambda \pEven[k+1]}.
  \end{equation}
  Так как $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in \left( \pOdd, \pEven[k+1] \right)$, то для $\lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]}$ справедливо аналогичное представление.
  Приведя подобные в (\ref{eq:first:combination:game:1}), получим
  \begin{multline}
    \label{eq:first:combination:game:2}
    \lowerBound{p} = \frac{1}{1-\beta^2} 
    \left(\alpha\beta\lambda + \alpha\lambda\lowerBound{\pEven} + (1-\lambda)\lowerBound{\pOdd[k+1]} + \right.\\
    % 
    \left. + \beta
      \left(
        \alpha\beta(1-\lambda) + (1-\lambda)\alpha\lowerBound{\pEven} + \lambda\alpha\lowerBound{\pOdd[k+1]}
      \right)
    \right) = \\
    % 
    = \frac{1}{2} \left(
      (k + 1)(m - k - 1) + \alpha\lambda(2k - m + 2\beta + 1)
    \right) = \\
    = \lambda\lowerBound{\pOdd} + (1-\lambda)\lowerBound{\pEven[k+1]}.
  \end{multline}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd, \, k = \overline{1, m - 1}$.
  В этом случае при использовании $\lambda\fEven + (1-~\lambda)\fOdd$ первый игрок рандомизирует между ставками $k$ и $k+1$ с параметрами
  \begin{gather*}
    q_k = \lambda\beta + (1-\lambda)(1-\beta), \:
    p(H|k) = \frac{\lambda\beta}{q_k}\pOdd[k-1] +
      \frac{(1-\lambda)(1-\beta)}{q_k} \pEven,\\
    q_{k+1} = \lambda(1-\beta) + (1-\lambda)\beta, \:
    p(H|k+1) = \frac{\lambda(1-\beta)}{q_{k+1}}\pOdd[k] +
      \frac{(1-\lambda)\beta}{q_{k+1}}\pEven[k+1].
  \end{gather*}
  
  Заметим, что $p(H|k) \in \left( \pOdd[k-1], \pEven \right)$, а $p(H|k+1) \in \left( \pOdd, \pEven[k+1] \right)$.
  Тогда с помощью (\ref{eq:first:combination:game:2}) получим
  \begin{multline*}
    \lowerBound{p} = \lambda \beta \lowerBound{\pOdd[k-1]} + (1-\lambda)(1-\beta)\lowerBound{\pEven} + \lambda(1-\beta)\lowerBound{\pOdd} + \\
      + (1-\lambda)\beta\lowerBound{\pEven[k+1]} =
    \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}.
  \end{multline*}
  
  При $p \in \left( 0, \pOdd[1] \right)$ и $p \in \left( \pOdd[m-1], 1 \right)$ доказательство проводится аналогично.
\end{proof}

Заметим, что при $\beta < 1/2$ полученные результаты также имеют место, а стратегию $\fOpt$ можно получить, рассмотрев дополнительную игру $\symm{\infiniteGame{p}}$.
Таким образом, мы определили $\lowerBound{p}$ и $\fOpt$ для $p \in [0, 1], \, \beta \in [0, 1]$.

\begin{lemma}
  \label{lemma:first:lower}
  При использовании первым игроком стратегии $\fOpt$ в игре $\infiniteGame{p}$, его выигрыш ограничен снизу функцией $\lowerBound{p}$, т.е.
  \[
  \min_{\tau \in \Tau} \infiniteFirstPlayerPayoff{p}{\fOpt}{\tau} \geq \lowerBound{p}.
  \]
\end{lemma}

Отметим, что приведенная стратегия инсайдера для $p \in [0, 1] \setminus P$ принципиально отличается от аналогичной стратегии в \cite{pyanykh14}, которая дает необходимые результаты только при $\beta = 1/2$.

\begin{theorem}
  Игра $\infiniteGame{p}$ имеет значение $\infiniteGameValue{p} = \upperBound{p} = \lowerBound{p}$, при этом $\fOpt$ -- оптимальная стратегия первого игрока, $\tau^*$ -- оптимальная стратегия второго игрока.
\end{theorem}
Доказательство по форме повторяет доказательство аналогичной теоремы в работе \cite{domansky07}.

%
% Список литературы
%
\renewcommand{\refname}{\begin{center}
{\normalsize \rm СПИСОК ЛИТЕРАТУРЫ} \end{center}}
%
\begin{thebibliography}{99}\itemsep=-2pt
  \selectlanguage{english}
  \bibitem{aumann95-rep}%
    Aumann R.\,J., Maschler M.\,B.\,: Repeated games with incomplete information. The MIT Press. 1995.

  \selectlanguage{english}
  \bibitem{chatterjee83}
    Chatterjee K., Samuelson W.\,: Bargaining under Incomplete Information~// Operations Research. 1983. {\bfseries 31}. P.\, 835--851.

  \selectlanguage{english}
  \bibitem{demeyer02}
    De Meyer B., Saley H.\,: On the strategic origin of Brownian motion in finance~// Int J Game Theory. 2002. {\bfseries 31}. P.\, 285--319.
    
  \selectlanguage{english}
  \bibitem{domansky07}%
    Domansky V.\,: Repeated games with asymmetric information and random price fluctuations at finance markets~// Int J Game Theory. 2007. {\bfseries 36}. N~2. P.\, 265--281.

  \selectlanguage{russian}
  \bibitem{kreps09}%
    Крепс В.\,Л.\,: Повторяющиеся игры, моделирующие биржевые торги, и возвратные последовательности~// Изв. РАН. Теория и системы управления. 2009. {\bfseries 4}. С.\, 109--120.

  \selectlanguage{russian}
  \bibitem{sandomirskaya12}
    Сандомирская М.\,С., Доманский В.\,К.\,: Решение одношаговой игры биржевых торгов с неполной информацией~// Математическая Теория Игр и ее Приложения. 2012. {\bfseries 4}. №~1. С.\, 32-54.

  \selectlanguage{russian}
  \bibitem{pyanykh14}%
    Пьяных А.\,И.\,: Об одной модификации модели биржевых торгов с инсайдером~// Математическая теория игр и ее приложения. 2014. {\bfseries 6}. №~4. С.\, 68--84.
    
  \selectlanguage{russian}
  \bibitem{samarsky89-num}%
    Самарский А.\,А., Гулин А.\,В.\,: Численные методы. М.: Наука, 1989.
\end{thebibliography}
% 
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Character code reference %%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%     Upper case russian letters (CP1251): АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ  %                                                                       %
%     Lower case russian letters (CP1251): абвгдеёжзийклмнопрстуфхцчшщъыьэюя  %
%                     Upper case letters: ABCDEFGHIJKLMNOPQRSTUVWXYZ          %
%                     Lower case letters: abcdefghijklmnopqrstuvwxyz          %
%                                   Digits: 0123456789                        %
% Square, curly, angle braces, parentheses: [] {} <> ()                       %
%                Backslash, slash, solidus: \ / |                             %
%       Period, interrogative, exclamation: . ? !                             %
%                 Comma, colon, semi-colon: , : ;                             %
%          Underscore, hyphen, equals sign: _ - =                             %
%             Quotes (left, right, double): ` ' "                             %
%     Commercial-at, hash, dollar, percent: @ # $ %                           %
%  Ampersand, asterisk, plus, caret, tilde: & * +   ^                         %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
