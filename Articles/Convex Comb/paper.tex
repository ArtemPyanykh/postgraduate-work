% -*- coding: cp1251 -*- %
\documentclass[12pt, a4paper]{article}
\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}

\usepackage[centertags]{amsmath}
\usepackage{amsthm,amsfonts,amssymb}
\usepackage{indentfirst}
%-------------------------------------------------------------------------------
\frenchspacing
\parindent=0.6cm
\parskip=2pt
\mathsurround=1pt
%
\makeatletter
\renewcommand{\@biblabel}[1]{#1.}
\makeatother
%
\topskip=0mm
\headsep=0mm
\topmargin=0mm
\headheight=0mm
\textwidth=165mm
\textheight=240mm
\oddsidemargin=0mm

\renewcommand{\baselinestretch}{1.3}
%--------------------------------------------------------------------------

\newtheoremstyle{light}% <name>
 {}% <Space above>
 {}% <Space below>
 {\itshape}% <Body font>
 {}% <Indent amount>
 {\normalfont}% <Theorem head font>
 {.}% <Punctuation after theorem head>
 {.5em}% <Space after theorem headi>
 {}% <Theorem head spec (can be left empty, meaning `normal')>

\theoremstyle{light}

\newtheorem{lemma}{\indent Л е м м а }
\newtheorem*{theorem*}{\indent Т е о р е м а }
\newtheorem{proposition}{\indent У т в е р ж д е н и е }
\newtheorem{remark}{\indent З а м е ч а н и е }
\def\proof{{\indent Д о к а з а т е л ь с т в о.}}

\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

%%%%%%%%%%   Custom commands   %%%%%%%%%%%%%%
\newcommand{\Tau}{%
\mathrm{T}
}

\newcommand{\states}{%
\left\{H, L\right\}
}

\newcommand{\generalGame}[2]{%
G_{#1}^{m, \beta}\left({#2}\right)%
}

\newcommand{\infiniteGame}[1]{%
G_{\infty}^{m, \beta}\left({#1}\right)%
}

\newcommand{\firstPlayerPayoff}[4]{%
K_{#1}^{m,\beta}\left({#2}, {#3}, {#4}\right)%
}

\newcommand{\infiniteFirstPlayerPayoff}[3]{%
K_{\infty}^{m,\beta}\left({#1}, {#2}, {#3}\right)%
}

\newcommand{\gameValue}[2]{%
V_{#1}^{m,\beta}\left({#2}\right)%
}

\newcommand{\infiniteGameValue}[1]{%
V_{\infty}^{m,\beta}\left({#1}\right)%
}

\newcommand{\symm}[1]{%
\overline{#1}%
}

\newcommand{\symmGameExpression}[2][\infty]{%
G_{#1}^{m, \alpha}\left({#2}\right)%
}

\newcommand{\upperBound}[1]{%
H_{\infty}^{m,\beta}\left({#1}\right)%
}

\newcommand{\fGeneral}[2][1]{%
\sigma_{#1}^{#2}%
}

\newcommand{\pEven}[1][k]{%
p^0_{#1}%
}

\newcommand{\pOdd}[1][k]{%
p^{\beta}_{#1}%
}

\newcommand{\fEven}[1][k]{%
\phi^0_{#1}%
}

\newcommand{\fOdd}[1][k]{%
\phi^{\beta}_{#1}%
}

\newcommand{\fOpt}{\sigma^*}

\newcommand{\lowerBound}[2][\infty]{%
L_{#1}^{m,\beta}\left({#2}\right)%
}
%%%%%%%%%% End custom commands %%%%%%%%%%%%%%

\begin{document}

\noindent УДК 519.832.2
\medskip

{\bfseries
А.\,И. Пьяных\footnote{Факультет ВМК МГУ, асп.,
                       e--mail: artem.pyanykh@gmail.com},
\medskip

МНОГОШАГОВАЯ МОДЕЛЬ БИРЖЕВЫХ ТОРГОВ С \\
\indent АСИММЕТРИЧНОЙ ИНФОРМАЦИЕЙ И ЭЛЕМЕНТАМИ \\
\indent ПЕРЕГОВОРОВ 
}

\begin{quotation}{\footnotesize
  Рассматривается модификация дискретной многошаговой модели биржевых торгов.
  Два игрока ведут между собой торги рисковыми ценными бумагами (акциями).
  Один из игроков (инсайдер) знает настоящую цену акции, второй знает только ее вероятностное распределение.
  На каждом шаге торгов игроки делают целочисленные ставки.
  Игрок, предложивший большую ставку, покупает у другого акцию, причем цена сделки определяется как выпуклая комбинация предложенных ставок с некоторым заданным коэффициентом.
  Получено решение игры бесконечной продолжительности.
  \\
  \indent\textit{Ключевые слова}: многошаговые игры, асимметричная информация, повторяющиеся игры с неполной информацией.}
\end{quotation}
\medskip

{\bfseries 1. Введение.}\ В работе \cite{demeyer02} была рассмотрена многошаговая модель биржевых торгов однотипными акциями, в которой торги между собой ведут два игрока.
Перед началом торгов случайный ход определяет цену акции на весь период торгов. В состояниях рынка $L$ и $H$ цена акции равна $0$ и $m \in \mathbb{N}$ соответственно.
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй знает, что первый игрок --- инсайдер.
Оба игрока знают вероятность $p$ высокой цены акции.
На каждом шаге торгов оба игрока одновременно и независимо назначают некоторую цену за акцию.
Игроки могут делать произвольные вещественные ставки, причем игрок, предложивший б\'{о}льшую цену, покупает у другого акцию по названной цене.
Игроки помнят предложенные цены на всех предыдущих этапах торгов.
Задачей игрока является максимизация стоимости портфеля, состоящего из некоторого числа акций и суммы денег.
Модель сводится к повторяющейся игре с неполной информацией, как описано в \cite{aumann95-rep}, для которой Де Мейером и Салей \cite{demeyer02} были найдены оптимальные стратегии игроков и значение игры.

Позднее В. Доманским \cite{domansky07} была рассмотрена модификация модели, в которой ставки игроков могли принимать только целые значения. В данной постановке им было получено решение для игры неограниченной продолжительности.
Отметим работу В. Крепс \cite{kreps09} с явным решением для $n$-шаговых игр при $m \leq 3$, а также работу М. Сандомирской и В. Доманского \cite{sandomirskaya12} с решением одношаговой игры при произвольном $m \in \mathbb{N}$.

Рассмотрим следующий механизм формирования цены акции, предложенный в \cite{chatterjee83}.
Игроки одновременно предлагают цены $i$ и $j$.
При $i > j$ акция продается по цене $\beta i + (1-\beta) j$, где $\beta \in [0, 1]$ --- заданный коэффициент, характеризующий переговорную силу продавца.
В работе \cite{domansky07} фактически $\beta = 1$.
Решение задачи при значении $\beta = 1/2$ получено в \cite{pyanykh14}.
В данной работе решение бесконечной игры найдено при произвольном $\beta \in [0, 1]$.

{\bfseries 2. Модель игры.}\ Пусть множество состояний рынка $ S = \states $. На первом шаге случай выбирает $ s \in S $ с вероятностями $ p(H) = p $ и $ p(L) = 1 - p $.
После этого на протяжении $ n \leq \infty $ шагов игроки играют в игру с матрицей $A^{s,\beta}$, где при $\alpha = 1-\beta$ 
\begin{equation*}
  A^{L,\beta}(i, j) = \begin{cases}
    \alpha i + \beta j, &\, i < j, \\
    0, &\, i = j, \\
    -\beta i - \alpha j, &\, i > j,
  \end{cases}
  \qquad
  A^{H,\beta}(i, j) = \begin{cases}
    \alpha i + \beta j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \beta i - \alpha j, &\, i > j.
  \end{cases}
\end{equation*}

На $ t $-м шаге первый игрок выбирает ставку $ i_t \in I = \{0, 1, \ldots, m\} $, а второй --- ставку $ j_t \in J = \{0, 1, \ldots, m\} $. 
Выигрыш первого игрока в повторяющейся игре равен $ \sum\limits_{t=1}^n a_{i_t j_t}^{s,\beta} $.
Второму игроку этот выигрыш становится известным только после окончания игры.
На промежуточных шагах он не имеет точной информации о величинах $ a_{i_t j_t}^{s,\beta} $.

Таким образом, стратегией первого игрока является последовательность ходов
$
  \sigma = (\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots),
$
где $\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$, а $\Delta(I)$ --- множество вероятностных распределений на $I$.
Как и в \cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий первого игрока обозначим через $\Sigma$.
Аналогично стратегией второго игрока назовем последовательность ходов
$
  \tau = (\tau_1, \tau_2, \ldots, \tau_t, \ldots),
$
где $ \tau_t: I^{t-1} \rightarrow \Delta(J) $.
Множество стратегий второго игрока обозначим через $\Tau$.

При применении первым игроком смешанной стратегии
$ \sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n) $, где 
$ 
  \sigma_t~=~(\sigma_t^L, \sigma_t^H), \quad
  \sigma^s_t~=~(\sigma^s_{t, 0}, \ldots, \sigma^s_{t, m}) \in \Delta(I),
$ 
а вторым игроком смешанной стратегии 
$ \tau~=~(\tau_1, \tau_2, \ldots, \tau_n) $, где
$ \tau_t~=~(\tau_{t, 0}, \ldots, \tau_{t, m}) \in \Delta(J) $,
ожидаемый выигрыш первого игрока равен
\begin{equation}
  \label{eq:firstPlayerPayoff}
  \firstPlayerPayoff{n}{p}{\sigma}{\tau} = \sum_{t=1}^n
  \left(
    pA^{H,\beta}(\sigma_t^H, \tau_t) + (1 - p)A^{L,\beta}(\sigma_t^L, \tau_t)
  \right),
\end{equation}
где 
$ 
A^{s,\beta}(\sigma^s_t,\tau_t) = 
    \sum\limits_{i \in I}
        \sum\limits_{j \in J}
            \sigma^s_{t, i} \tau_{t, j} A^{s,\beta}(i, j).
$
Полученную игру обозначим через $\generalGame{n}{p}$, а ее значение через $\gameValue{n}{p}$.

Заметим, что $A^{L,\beta}(i,j) = A^{H,\alpha}(m-i,m-j), \, A^{H,\beta}(i,j) = A^{L,\alpha}(m-i,m-j)$.
Определим симметричные по отношению к $\sigma$ и $\tau$ стратегии игроков
$
  \symm{\sigma_t} = (\symm{\sigma^H_t}, \symm{\sigma^L}),
$
где 
$
  \symm{\sigma^s_t} = (\sigma^s_{t,m},\ldots,\sigma^s_{t,0}) \in \Delta(I),
$ 
и
$
  \symm{\tau_t} = (\tau_{t,m},\ldots,\tau_{t,0}) \in \Delta(J)
$.
Также введем обозначение $\symm{\generalGame{n}{p}} = \symmGameExpression[n]{1-p}$.
Легко видеть, что выигрыши игроков в играх $\generalGame{n}{p}$ и $\symm{\generalGame{n}{p}}$ при использовании симметричных стратегий совпадают.

{\bfseries 3. Оценка сверху выигрыша первого игрока.}\ Следуя \cite{domansky07}, рассмотрим чистую стратегию второго игрока $\tau^k, \, k \in J$:
\[
  \tau^k_1 = k, \quad
  \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]

По сути эта стратегия представляет собой стратегию подражания инсайдеру.
Доказательство следующего утверждения проводится по индукции.

\begin{proposition}
  \label{proposition:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\generalGame{n}{p}$ второй игрок гарантирует себе проигрыш не более
  \[
    h_n^L(\tau^k) = \sum_{t=0}^{n-1}(k - t - \alpha)^+, \quad
    h_n^H(\tau^k) = \sum_{t=0}^{n-1}(m - k - t - \beta)^+,
  \]
  в состояниях L и H соответственно, где $x^+ = \max(x; 0)$ для $x \in \mathbb{R}$.
\end{proposition}

Очевидно, что $h_n^L(\tau^k)$ и $h_n^H(\tau^k)$ монотонны и ограничены сверху по $n$.
Введем следующую функцию:
\begin{multline*}
  \upperBound{p} = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  %
  = \min_{j \in J} \left[
    p (m - j)(m - j + \alpha - \beta) + (1 - p)j(j + \beta - \alpha)
  \right] / 2.
\end{multline*}

При $p \in \left( (k-\alpha)/m, (k+\beta)/m) \right]$ минимум по $j \in J$ достигается при $j = k$.
Таким образом, $\upperBound{p}$ является кусочно-линейной функцией, состоящей из $m~+~1$ линейных сегментов, и полностью определяется своими значениями в точках
\begin{gather*}
  \upperBound{(k+\beta)/m} = \left(
  (m - (k + \beta))(k + \beta) + \alpha\beta
  \right) / 2, \enskip 
  k = \overline{0, m - 1},\\
  \upperBound{0} = \upperBound{1} = 0.
\end{gather*}

Пусть второй игрок при $p \in \left( (k-\alpha)/m, (k+\beta)/m) \right]$ применяет $\tau^k, \, k = \overline{0, m}$. Обозначим эту стратегию через $\tau^*$. Тогда справедлива следующая

\begin{lemma}
  \label{lemma:upperBound} 
  При использовании вторым игроком стратегии $\tau^*$ в игре $\infiniteGame{p}$\textup{,} выигрыш первого игрока ограничен сверху функцией $\upperBound{p}$, т.е.
  \[
  \max_{\sigma \in \Sigma} 
    \infiniteFirstPlayerPayoff{p}{\sigma}{\tau^*}
  \leq \upperBound{p}.
  \]
\end{lemma}

{\bfseries 4. Оценка снизу выигрыша первого игрока.}\ Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее $\upperBound{p}$ в игре $\infiniteGame{p}$.
Пусть на первом шаге игрок применяет 
$
\fGeneral{k}~=~\left(\fGeneral{H}, \fGeneral{L}\right)
$, где 
$\fGeneral{H} = \left(\fGeneral[1,k]{H}, \fGeneral[1,k+1]{H}\right)$,
$\fGeneral{L} = \left(\fGeneral[1,k]{L}, \fGeneral[1,k+1]{L}\right)$ и
$\fGeneral[1,i]{s}$ -- вероятность сделать ставку $i$ в состоянии $s \in \states$.
Применяя $\fGeneral{k}$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

Определим следующие параметры: полные вероятности действий $k$ и $k+1$, равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\fGeneral[1,i]{s}$ можно найти по формуле Байеса
$
\fGeneral[1,i]{s}~=~p(s|i)q_i/p(s), \: i = k, k + 1.
$

\begin{proposition}
  При использовании $\fGeneral{k}$ первый игрок гарантирует себе на первом шаге выигрыш
  \begin{equation}
    \label{eq:lowerPayoffGeneral}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} =
    \begin{cases}
      mp - \beta k - \alpha j - \beta q_{k+1},      & \, j < k,     \\
      \left(m p(H|k+1) - k - \beta \right) q_{k+1}, & \, j = k,     \\
      \left(k + \beta - m p(H|k) \right) q_k,       & \, j = k + 1, \\
      \alpha k + \beta j - mp + \alpha q_{k+1},     & \, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}

Доказательство следует из (\ref{eq:firstPlayerPayoff}) и определения $\fGeneral{k}$.

Построим оптимальную стратегию инсайдера.
Рассмотрим на $[0,1]$ множество $P$ точек вида
\[
\pEven[i] = i/m, \, i = \overline{0, m}, \quad
\pOdd[i] = (i + \beta)/m, \, i = \overline{0, m - 1}.
\]

Для $p = \pEven$ определим $\fEven$ как действие $\fGeneral{k}$ с параметрами
\begin{equation*}
  p(H|k) = \pOdd[k-1], \quad p(H|k + 1) = \pOdd[k], \quad q_k = \beta, \quad q_{k+1} = \alpha.
\end{equation*}
Дополнительно определим $\fEven[0]$ как действие, состоящее в применении ставки $0$ с вероятностью $1$, а $\fEven[m]$ -- как действие, состоящее в применении ставки $m$ с вероятностью $1$.
Аналогично для $p = \pOdd$ определим $\fOdd$ как действие $\fGeneral{k}$ с параметрами
\begin{equation*}
  p(H|k) = \pEven[k], \quad p(H|k + 1) = \pEven[k+1], \quad q_k = \alpha, \quad q_{k+1} = \beta.
\end{equation*}

\begin{proposition}
  При $p \in P$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{j}$ выигрыша первого игрока верны оценки
  \begin{equation}
    \label{eq:lowerBound:inequalities}
    \min_{j \in J}
    \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0,
    \quad
    \min_{j \in J}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} \geq \alpha\beta.
  \end{equation}
\end{proposition}
Справедливость утверждения устанавливается подстановкой $\fEven$ и $\fOdd$ в (\ref{eq:lowerPayoffGeneral}).

Заметим, что если $p \in P$, то при применении инсайдером на первом шаге игры $\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих шагах игры, тем самым определив стратегию $\fOpt$ в игре
$\generalGame{n}{p}$, где $p \in P, \, n \in \mathbb{N}$.

Пусть $\lowerBound[n]{p}$ при $p \in P$ --- гарантированный выигрыш первого игрока в игре $\generalGame{n}{p}$ при применении стратегии $\fOpt$.
В силу рекурсивной структуры игры $\generalGame{n}{p}$ (см. \cite{domansky07}) и неравенств (\ref{eq:lowerBound:inequalities}) для $\lowerBound[n]{p}$ справедливы формулы
\begin{equation}
  \begin{gathered}
    \label{eq:lowerBound:recurrence:function}
    \lowerBound[n]{(k + \beta)/m} = \alpha\beta +
      \alpha\lowerBound[n-1]{k/m} +
      \beta\lowerBound[n-1]{(k + 1)/m}, \: k = \overline{0, m-1}, \\
    % 
    \lowerBound[n]{k/m} = \beta\lowerBound[n-1]{(k - 1 + \beta)/m} +
      \alpha\lowerBound[n-1]{(k + \beta)/m}, \: k = \overline{1, m-1}, \\
    % 
    \lowerBound[n]{0} = \lowerBound[n]{1} = 0.
  \end{gathered}
\end{equation}

Так как $\lowerBound[n]{p}$ не убывает по $n$ и ограничена сверху, то устремив $n$ к бесконечности, получим нижнюю оценку $\lowerBound{p}$ выигрыша первого игрока в игре $\infiniteGame{p}, \, p \in P$.

Введем следующие обозначения:
\[
L_{2k} = \lowerBound{k/m}, \, k = \overline{0,m}, \enskip%
L_{2k+1} = \lowerBound{(k+\beta)/m)}, \, k = \overline{0,m-1}.
\]
Тогда справедливы формулы
\begin{equation}
  \label{eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \alpha\beta + \alpha L_{2k} + \beta L_{2(k+1)}, \enskip k = \overline{0, m-1},\\
    L_{2k} = \beta L_{2k-1} + \alpha L_{2k+1}, \enskip k = \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

\begingroup\setlength{\medmuskip}{0mu}
Введем $(2m-1)\times(2m-1)$-матрицу $B$ и $(2m-1)$-вектор-столбец $b$:
\endgroup
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\beta  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\beta & 1       & -\alpha & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\alpha & 1       & -\beta & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\beta & 1       & -\alpha \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\alpha & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \alpha\beta \\
      0           \\
      \alpha\beta \\
      \cdots      \\
      0           \\
      \alpha\beta
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{eq:lowerRecurrence}) перепишем в виде 
$
BL = b, L_0 = L_{2m} = 0,
$
где 
$L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
M = \left(\begin{array}{ccccccc}
c_1 & b_1 & 0   & \cdots & 0       & 0       & 0       \\
a_2 & c_2 & b_2 & \cdots & 0       & 0       & 0       \\
\hdotsfor{7}                                           \\
0   & 0   & 0   & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
0   & 0   & 0   & \cdots & 0       & a_n     & c_n
\end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для прогоночных коэффициентов и переменных (см. \cite{samarsky89-num}):
\begin{gather*}
  x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1}, \quad
  x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
  % 
  \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2, n-1}, \quad
  \gamma_2 = -\frac{b_1}{c_1}, \\
  % 
  \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i = \overline{2, n-1}, \quad
  \delta_2 = \frac{f_1}{c_1}.
\end{gather*}

\begin{proposition}
  \label{proposition:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими формулами\textup{:}
  \begin{multline*}
    \gamma_{2k} = \frac{\beta+k-1}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\beta}, \\
    \delta_{2k} = \frac{\alpha(k-1+2\beta)}{2}, \,
    \delta_{2k+1} = \frac{k\beta(k-1+2\beta)}{2(k+\beta)}, \quad k = \overline{1,m-1}.
  \end{multline*}
\end{proposition}
Данное утверждение доказывается по индукции.

Из (\ref{eq:lowerRecurrence}) следует, что $L_{2k-1} = \gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} + \delta_{2k}, \, k = \overline{1, m-1}$.
Подстановкой $\upperBound{(k+\beta)/m}$ вместо $L_{2k+1}$ это равенство обращается в тождество. Тем самым доказано

\begin{proposition}
  \label{proposition:lower:recurrence-solution}
  Решение системы {\normalfont(\ref{eq:lowerRecurrence})} дается следующими формулами\textup{:}
  \begin{gather*}
    L_{2k+1} = ((m - (k + \beta))(k + \beta) + \alpha\beta)/2, \, k = \overline{0, m-1}, \quad
    L_{2k} = k (m-k)/2, \, k = \overline{0,m}.
  \end{gather*}
\end{proposition}

Итак, мы определили функцию $\lowerBound{p}$ при $p \in P$.
Для $p \in [0, 1] \setminus P$ стратегия инсайдера основана на применении выпуклой комбинации стратегий для крайних точек интервала, в котором находится $p$.

\begin{proposition}
  \label{proposition:first:combination:step}
  При $\lambda \in (0, 1), \, \beta \geq 1/2, \, k = \overline{0, m-1}$ для значения выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{j \in J}
      \firstPlayerPayoff{1}{%
        \lambda \pEven + (1-\lambda) \pOdd}{%
        \lambda \fEven + (1-\lambda) \fOdd}{%
        j}
      &\geq \alpha \beta (1-\lambda), \\
      %
    \min_{j \in J}
      \firstPlayerPayoff{1}{%
        \lambda \pOdd + (1-\lambda) \pEven[k+1]}{%
        \lambda \fOdd + (1-\lambda) \fEven[k+1]}{%
        j}
      &\geq \alpha \beta \lambda.
  \end{align*}
\end{proposition}
Утверждение следует из линейности $\firstPlayerPayoff{1}{p}{\sigma}{j}$ по $\sigma$ и равенства (\ref{eq:lowerPayoffGeneral}).

\begin{proposition}
  \label{proposition:first:combination:game}
  При $\lambda \in (0, 1), \, \beta \geq 1/2, \, k = \overline{0, m-1}$, для гарантированного выигрыша первого игрока в игре $\infiniteGame{p}$ справедливы равенства
  \begin{align*}
    \lowerBound{\lambda \pEven + (1-\lambda) \pOdd}      & = 
      \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}, \\
    \lowerBound{\lambda \pOdd + (1-\lambda) \pEven[k+1]} & =
      \lambda \lowerBound{\pOdd} + (1-\lambda) \lowerBound{\pEven}.
  \end{align*}
\end{proposition}
\begin{proof}
  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1]$, где $k = \overline{0, m - 2}, \, \lambda \in (0, 1)$.
  Обозначим через $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ распределение, при котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
  \begin{gather*}
    q_k = \lambda\alpha, \, q_{k+1} = \beta, \, q_{k+2} = (1-\lambda)\alpha,\\
    p(H|k) = \pEven, \, p(H|k+1) = \lambda \pEven[k+1] + (1-\lambda) \pOdd, \, p(H|k+2) = \pOdd[k+1].
  \end{gather*}
  
  Тогда по аналогии с (\ref{eq:lowerBound:recurrence:function}) выписывается следующая рекуррентная формула:
  \[
    \lowerBound{p} = \alpha \beta \lambda +
      \lambda \alpha \lowerBound{\pEven} +
      (1-\lambda) \alpha \lowerBound{\pOdd[k+1]} +
      \beta \lowerBound{(1-\lambda) \pOdd + \lambda \pEven[k+1]}.
  \]
  Так как $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in \left( \pOdd, \pEven[k+1] \right)$, то для $\lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]}$ справедливо аналогичное представление.
  Приведя подобные члены, получим
  \begin{multline}
    \label{eq:first:combination:game:2}
    \lowerBound{p} = \frac{1}{1-\beta^2} 
    \left(\alpha\beta\lambda + \alpha\lambda\lowerBound{\pEven} + (1-\lambda)\alpha\lowerBound{\pOdd[k+1]} + \right.\\
    % 
    \left. + \beta
      \left(
        \alpha\beta(1-\lambda) + (1-\lambda)\alpha\lowerBound{\pEven} + \lambda\alpha\lowerBound{\pOdd[k+1]}
      \right)
    \right) = \\
    % 
    = \left(
      (k + 1)(m - k - 1) + \alpha\lambda(2k - m + 2\beta + 1)
    \right)/2 = \\
    = \lambda\lowerBound{\pOdd} + (1-\lambda)\lowerBound{\pEven[k+1]}.
  \end{multline}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd$, где $k = \overline{1, m - 1}, \, \lambda \in (0, 1)$.
  Обозначим через $\lambda\fEven + (1-~\lambda)\fOdd$ распределение, при котором первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
  \begin{gather*}
    q_k = \lambda\beta + (1-\lambda)(1-\beta), \:
    p(H|k) = \frac{\lambda\beta}{q_k}\pOdd[k-1] +
      \frac{(1-\lambda)(1-\beta)}{q_k} \pEven,\\
    q_{k+1} = \lambda(1-\beta) + (1-\lambda)\beta, \:
    p(H|k+1) = \frac{\lambda(1-\beta)}{q_{k+1}}\pOdd[k] +
      \frac{(1-\lambda)\beta}{q_{k+1}}\pEven[k+1].
  \end{gather*}
  
  Заметим, что $p(H|k) \in \left( \pOdd[k-1], \pEven \right)$, а $p(H|k+1) \in \left( \pOdd, \pEven[k+1] \right)$.
  Тогда с помощью (\ref{eq:first:combination:game:2}) получим
  \begin{multline*}
    \lowerBound{p} = \lambda \beta \lowerBound{\pOdd[k-1]} + (1-\lambda)(1-\beta)\lowerBound{\pEven} + \lambda(1-\beta)\lowerBound{\pOdd} + \\
      + (1-\lambda)\beta\lowerBound{\pEven[k+1]} =
    \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}.
  \end{multline*}
  
  При $p \in \left( 0, \pOdd[1] \right)$ и $p \in \left( \pOdd[m-1], 1 \right)$ доказательство проводится аналогично.
\end{proof}

Заметим, что при $\beta < 1/2$ полученные результаты также имеют место, а стратегию $\fOpt$ можно получить, рассмотрев игру $\symm{\infiniteGame{p}}$.
Таким образом, мы определили $\lowerBound{p}$ и $\fOpt$ для любых $p \in [0, 1], \, \beta \in [0, 1]$.

\begin{lemma}
  \label{lemma:first:lower}
  При использовании первым игроком стратегии $\fOpt$ в игре $\infiniteGame{p}$\textup{,} его выигрыш ограничен снизу функцией $\lowerBound{p}$\textup{,} т.е.
  \[
  \min_{\tau \in \Tau} \infiniteFirstPlayerPayoff{p}{\fOpt}{\tau} \geq \lowerBound{p}.
  \]
\end{lemma}

Отметим, что приведенная стратегия инсайдера для $p \in [0, 1] \setminus P$ принципиально отличается от его стратегии в \cite{pyanykh14}, которая оптимальна только при $\beta = 1/2$.

\begin{theorem*}
  Игра $\infiniteGame{p}$ имеет значение $\infiniteGameValue{p} = \upperBound{p} = \lowerBound{p}$.
  При этом $\fOpt$ -- оптимальная стратегия первого игрока\textup{,} а $\tau^*$ -- оптимальная стратегия второго игрока.
\end{theorem}
Доказательство по форме повторяет доказательство аналогичной теоремы в \cite{domansky07}.

\vspace{-3.5em}

%
% Список литературы
%
\renewcommand{\refname}{\begin{center}
{\normalsize \rm СПИСОК ЛИТЕРАТУРЫ} \end{center}}
%
\begin{thebibliography}{99}\itemsep=-2pt
  \selectlanguage{english}
  \bibitem{demeyer02}
    De Meyer B., Saley H. On the strategic origin of Brownian motion in finance~// Intern. J. Game Theory. 2002. {\bfseries 31}. N~2. P.\, 285--319.

  \selectlanguage{english}
  \bibitem{aumann95-rep}%
    Aumann R.\,J., Maschler M.\,B. Repeated Games with Incomplete Information. Cambridge, Massachusetts: The MIT Press, 1995.

  \selectlanguage{english}
  \bibitem{domansky07}%
    Domansky V. Repeated games with asymmetric information and random price fluctuations at finance markets~// Intern. J. Game Theory. 2007. {\bfseries 36}. N~2. P.\, 265--281.

  \selectlanguage{russian}
  \bibitem{kreps09}%
    Крепс В.\,Л. Повторяющиеся игры, моделирующие биржевые торги, и возвратные последовательности~// Известия РАН. Теория и системы управления. 2009. №~4. С.\, 109--120.

  \selectlanguage{russian}
  \bibitem{sandomirskaya12}
    Сандомирская М.\,С., Доманский В.\,К. Решение одношаговой игры биржевых торгов с неполной информацией~// Математическая теория игр и ее приложения. 2012. {\bfseries 4}. №~1. С.\, 32--54.

  \selectlanguage{english}
  \bibitem{chatterjee83}
    Chatterjee K., Samuelson W. Bargaining under incomplete information~// Operations Research. 1983. {\bfseries 31}. N~5. P.\, 835--851.

  \selectlanguage{russian}
  \bibitem{pyanykh14}%
    Пьяных А.\,И. Об одной модификации модели биржевых торгов с инсайдером~// Математическая теория игр и ее приложения. 2014. {\bfseries 6}. №~4. С.\, 68--84.
    
  \selectlanguage{russian}
  \bibitem{samarsky89-num}%
    Самарский А.\,А., Гулин А.\,В. Численные методы. М.: Наука, 1989.
\end{thebibliography}

\hfill\begin{tabular}{l}
Поступила в редакцию\\
15.04.15
\end{tabular}

% 
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Character code reference %%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%     Upper case russian letters (CP1251): АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ  %                                                                       %
%     Lower case russian letters (CP1251): абвгдеёжзийклмнопрстуфхцчшщъыьэюя  %
%                     Upper case letters: ABCDEFGHIJKLMNOPQRSTUVWXYZ          %
%                     Lower case letters: abcdefghijklmnopqrstuvwxyz          %
%                                   Digits: 0123456789                        %
% Square, curly, angle braces, parentheses: [] {} <> ()                       %
%                Backslash, slash, solidus: \ / |                             %
%       Period, interrogative, exclamation: . ? !                             %
%                 Comma, colon, semi-colon: , : ;                             %
%          Underscore, hyphen, equals sign: _ - =                             %
%             Quotes (left, right, double): ` ' "                             %
%     Commercial-at, hash, dollar, percent: @ # $ %                           %
%  Ampersand, asterisk, plus, caret, tilde: & * +   ^                         %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
